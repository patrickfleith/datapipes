{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVqavcfj0YTJZj/A5ClAkt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrickfleith/datapipes/blob/main/How_to_use_Anthropic_Claude_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use Anthropic Claude model\n",
        "In this notebook we look into:\n",
        "1. The basic on how to use an Anthropic model (Claude-3.5-Sonnet, and Claude-3.5-Haiku) with just a few lines of code\n",
        "2. Which settings you can play with to tune the behaviour of the model on your use case.\n"
      ],
      "metadata": {
        "id": "EmmlLw4H2F0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Table of content**\n",
        ">[Anthropic Setup](#folderId=1tp_6Ep8ifTiLdokzSoJhJccd212GnCHV&updateTitle=true&scrollTo=trNIWx9Av671)\n",
        "\n",
        ">[Simple inference with Claude model from Anthropic](#folderId=1tp_6Ep8ifTiLdokzSoJhJccd212GnCHV&updateTitle=true&scrollTo=UFa55z60wt72)\n",
        "\n",
        ">[Advanced Options](#folderId=1tp_6Ep8ifTiLdokzSoJhJccd212GnCHV&updateTitle=true&scrollTo=sLX3RCdD1FHF)\n",
        "\n",
        ">[Streaming](#folderId=1tp_6Ep8ifTiLdokzSoJhJccd212GnCHV&updateTitle=true&scrollTo=n2o2YPQl1t0s)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "j-HCVig92o0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anthropic Setup"
      ],
      "metadata": {
        "id": "trNIWx9Av671"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we have to install it (it i note available by default in Google Colab)\n",
        "!pip install anthropic --quiet"
      ],
      "metadata": {
        "id": "0ir6ypgVwIYe"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "f2uTnH7-tuEl"
      },
      "outputs": [],
      "source": [
        "import anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use an Anthropic Claude models, you'll need to create an API key and configure it in your Google Colab Secrets.\n",
        "\n",
        "\n",
        "1. Login or create an Anthropic account, and configure a billing method, on the Anthropic Console [here](https://console.anthropic.com/login).\n",
        "2. You'll also have to make provision a small amount of credit like $5 before you can start using the API.\n",
        "3. Create a secret api key from [here](https://console.anthropic.com/settings/keys)\n",
        "4. Open your Colab secrets (click on the key icon here on the left)\n",
        "3. Give a the name, for instance `ANTHROPIC_API_KEY`, and past the value in `Value`.\n",
        "4. Toggle `Notebook access` to give access to this specific notebook to the API key.\n",
        "\n",
        "ðŸ”‘ Note that this api key will now be available in your secrets everytime you open or create a new colab notebook. You'll however still need to grant explicit access to each notebook.\n",
        "\n",
        "\n",
        "ðŸ’¸ Using an OpenAI model you will get charged! Use a small and cheap model for testing and learning like `TBD` then switch to a better model if needed for more complex tasks.\n"
      ],
      "metadata": {
        "id": "Tsh_FlQwulOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')"
      ],
      "metadata": {
        "id": "98VRNCvPvD_E"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple inference with Claude model from Anthropic\n",
        "Text generation is very simple. You need to create an Antrhopic `client` object. You then call the `client.messages.create()` function and pass **the two most important parameters:**\n",
        "- ðŸ§  `model` the large language model being used.\n",
        "- ðŸ’¬ `messages` the list of user messages, and assistant responses.\n",
        "\n",
        "It is very similar to OpenAI.\n",
        "\n",
        "Note: However with Anthropic, the optional system prompt does not go into the messages list, instead, it is an extra argument **system** like illustrated below (more on system prompt with Claude [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts)."
      ],
      "metadata": {
        "id": "UFa55z60wt72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anthropic Models\n",
        "I recommend testing models in the following order (from cheaper to more expensive and better):\n",
        "1. `claude-3-5-haiku-latest` affordable, intelligent and balzing fast.\n",
        "    - Knowledge cut-off date: July 2024\n",
        "2. `claude-3-5-sonnet-latest` Their most intelligent model with highest level of intelligence and capability.\n",
        "    - Knowledge cut-off date: April 2024\n",
        "\n",
        "Both models have a 200k tokens (150k english words) context window limits, i.e. the maximum size of input messages.\n",
        "\n",
        "For pricing and more info, look [here](https://docs.anthropic.com/en/docs/about-claude/models#model-comparison-table)"
      ],
      "metadata": {
        "id": "T78jPP4dyKDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "\n",
        "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "response = client.messages.create(\n",
        "    model=\"claude-3-5-haiku-latest\",\n",
        "    max_tokens=2048,\n",
        "    system=\"You are a seasoned data scientist at a Fortune 500 company.\", # <-- system prompt\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What would you advsie to do as EDA for time series?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.content[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJnSG7KYwZtb",
        "outputId": "5a325a79-7aeb-4d70-dd4f-fe55c6745230"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When conducting Exploratory Data Analysis (EDA) for time series data, I recommend the following comprehensive approach:\n",
            "\n",
            "1. Preliminary Data Inspection\n",
            "- Check data timespan and frequency\n",
            "- Verify time column formatting\n",
            "- Identify missing values or gaps\n",
            "- Validate timestamp consistency\n",
            "\n",
            "2. Visualization Techniques\n",
            "- Line plots of time series\n",
            "- Seasonal decomposition plot\n",
            "- Box plots by time periods\n",
            "- Heatmaps of periodicity\n",
            "- Autocorrelation and partial autocorrelation plots\n",
            "- Rolling statistics visualization\n",
            "\n",
            "3. Statistical Characteristics\n",
            "- Compute descriptive statistics\n",
            "- Calculate:\n",
            "  - Mean\n",
            "  - Median\n",
            "  - Standard deviation\n",
            "  - Minimum/maximum values\n",
            "- Check for:\n",
            "  - Stationarity\n",
            "  - Trends\n",
            "  - Seasonality\n",
            "  - Cyclical patterns\n",
            "\n",
            "4. Advanced Analysis\n",
            "- Time series decomposition\n",
            "- Lag plots\n",
            "- Rolling window analysis\n",
            "- Correlation with external variables\n",
            "- Spectral analysis\n",
            "\n",
            "5. Distribution Assessment\n",
            "- Check data distribution\n",
            "- Identify outliers\n",
            "- Normality tests\n",
            "- Skewness and kurtosis\n",
            "\n",
            "6. Preprocessing Considerations\n",
            "- Handle missing values\n",
            "- Smoothing techniques\n",
            "- Normalization/standardization\n",
            "- Feature engineering\n",
            "\n",
            "Recommended Python libraries:\n",
            "- Pandas\n",
            "- Matplotlib\n",
            "- Seaborn\n",
            "- Statsmodels\n",
            "- Scipy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Options\n",
        "Here are some more advanced parameters you can use."
      ],
      "metadata": {
        "id": "sLX3RCdD1FHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "\n",
        "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "response = client.messages.create(\n",
        "    model=\"claude-3-5-haiku-latest\",\n",
        "    system=\"You are the World best poet\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Write a very short poem about an astronaut on the Moon\"}\n",
        "        ],\n",
        "    max_tokens=512,\n",
        "    temperature=0.8,\n",
        "    top_k=10\n",
        ")"
      ],
      "metadata": {
        "id": "QoI03ISU1KsT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF4fISGW32i_",
        "outputId": "54bc95d5-f040-4cc5-da94-70075716df01"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a short poem about an astronaut on the Moon:\n",
            "\n",
            "Footprints in dust, silence so deep,\n",
            "One small step where shadows creep,\n",
            "Earth hangs distant, blue and bright,\n",
            "Alone I stand in lunar light.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the full documentation, check [here](https://docs.anthropic.com/en/api/messages). However, below are what I think the most important parameters to be aware of.\n",
        "\n",
        "**Temperature**\n",
        "\n",
        "- The `temperature` is the amount of randomness injected into the response. Defaults to 1.0. Ranges from 0.0 to 1.0. Use temperature closer to 0.0 for analytical / multiple choice, and closer to 1.0 for creative and generative tasks. Note that even with temperature of 0.0, the results will not be fully deterministic\n",
        "\n",
        "**Maximum number of tokens**\n",
        "\n",
        "- `max_token` refers to The maximum number of tokens to generate before stopping. Note that it may stop *before*.\n",
        "\n",
        "**Top K**\n",
        "\n",
        "- `top_k` top_k (integer) Only sample from the top K options for each subsequent token.\n",
        "\n",
        "**System**\n",
        "\n",
        "- `system` (string) a prompt you can use to set a role for the assistant."
      ],
      "metadata": {
        "id": "hL3WnKZ04_nH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming\n",
        "\n",
        "Without streaming you have to wait until the full response is created by the model to see it.\n",
        "With **streaming** you see each token as soos as they are generated, like in the Claude AI Chat interface. Streaming provide a much better user experience.\n",
        "Otherwise, if you don't have user-facing apps, you may not need it."
      ],
      "metadata": {
        "id": "n2o2YPQl1t0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "\n",
        "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "with client.messages.stream(\n",
        "    max_tokens=1024,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello, tell me about Data Science tips for EDA of time series\"}],\n",
        "    model=\"claude-3-5-haiku-latest\",\n",
        ") as stream:\n",
        "  for text in stream.text_stream:\n",
        "      print(text, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKGsszS71uw4",
        "outputId": "d9eb1b40-8b66-46d8-b011-ed169124fc37"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some key tips for Exploratory Data Analysis (EDA) of time series data:\n",
            "\n",
            "1. Visualization Techniques\n",
            "- Line plots to show overall trend\n",
            "- Seasonal decomposition plots\n",
            "- Autocorrelation Function (ACF) plot\n",
            "- Partial Autocorrelation Function (PACF) plot\n",
            "- Rolling statistics visualization\n",
            "- Box plots for seasonal patterns\n",
            "\n",
            "2. Time Series Characteristics Analysis\n",
            "- Check stationarity (Augmented Dickey-Fuller test)\n",
            "- Identify trend components\n",
            "- Detect seasonality\n",
            "- Analyze cyclical patterns\n",
            "- Examine lag correlations\n",
            "\n",
            "3. Data Preprocessing\n",
            "- Handle missing values\n",
            "- Normalize/standardize time series\n",
            "- Remove outliers\n",
            "- Smooth data if needed\n",
            "- Create lag features\n",
            "- Seasonal differencing\n",
            "\n",
            "4. Statistical Techniques\n",
            "- Check time series distributions\n",
            "- Calculate rolling mean/variance\n",
            "- Compute moving averages\n",
            "- Use statistical tests for trend/seasonality\n",
            "- Analyze time series components\n",
            "\n",
            "5. Advanced Visualization Tools\n",
            "- Seaborn\n",
            "- Plotly\n",
            "- Matplotlib\n",
            "- Pandas time series plotting\n",
            "- Interactive visualization libraries\n",
            "\n",
            "6. Recommended Python Libraries\n",
            "- Pandas\n",
            "- NumPy\n",
            "- Statsmodels\n",
            "- Scipy\n",
            "- Scikit-learn\n",
            "- Prophet\n",
            "- pmdarima\n",
            "\n",
            "Would you like me to elaborate on any specific aspect?"
          ]
        }
      ]
    }
  ]
}