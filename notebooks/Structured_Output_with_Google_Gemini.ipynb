{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Structured Output with Google Gemini\n",
        "In order to build reliable pipelines in which LLMs consistent return output in the same format, we are using a **Structured Output**\n",
        "- This means that we define a blueprint for the output\n",
        "- We pass the 'blueprint' to the LLM\n",
        "- Then the LLM output will confirm to the blueprint.\n",
        "\n",
        "This 'blueprint' in the LLM jargon is often called a \"schema\".\n",
        "\n",
        "**To generate structured outputs with Anthropic, we'll use the library `instructor`**.\n",
        "This will make it very easy to switch between different model providers."
      ],
      "metadata": {
        "id": "w6Gx1TJgGCqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Google Gemini API"
      ],
      "metadata": {
        "id": "LSxQcVBTGNcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install instructor --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvKrsUW2HsqP",
        "outputId": "5a1519dd-028d-4afe-80b4-0540df4b3566"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/71.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "McHR_WXZFZR3"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "from pydantic import BaseModel\n",
        "from enum import Enum\n",
        "import instructor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "Cb5lAMSkF9HQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "qtpunraSF9qI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate JSON\n",
        "When the model is configured to output JSON, it responds to any prompt with JSON-formatted output.\n",
        "\n",
        "You can control the structure of the JSON response by supplying a schema. There are two ways to supply a schema to the model:\n",
        "\n",
        "- As text in the prompt\n",
        "- As a structured schema supplied through model configuration\n",
        "\n",
        "Both approaches work in both Gemini 1.5 Flash and Gemini 1.5 Pro."
      ],
      "metadata": {
        "id": "kfb4Zr6YGRgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class City(str, Enum):\n",
        "    aria = \"Aria\"\n",
        "    kniga = \"Kniga\"\n",
        "    aquabah = \"Aquabah\"\n",
        "    torini = \"Torini\"\n",
        "\n",
        "class Character(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "    city: City\n",
        "    job: str\n",
        "    two_sentences_background_story: str\n",
        "    inventory: list[str]"
      ],
      "metadata": {
        "id": "zawtOFFFGBrb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_client = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "pfljCwDpI9oc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = instructor.from_gemini(\n",
        "    client=google_client,\n",
        "    mode=instructor.Mode.GEMINI_JSON,\n",
        ")"
      ],
      "metadata": {
        "id": "Ie8M5Q2YI_EK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# note that client.chat.completions.create will also work\n",
        "player = client.messages.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a helpful table-top RPG gamemaster assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Generate an Archer character from Kniga for a low-fantasy RPG campaign. Be creative\"},\n",
        "    ],\n",
        "    response_model=Character,\n",
        ")"
      ],
      "metadata": {
        "id": "EcMR-pvUIGN5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "player"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4rfZVhvJGYd",
        "outputId": "830b7d34-f984-482f-8a52-562daf47a70e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Character(name='Liliana', age=26, city=<City.kniga: 'Kniga'>, job='Archer', two_sentences_background_story='Liliana grew up in the forests outside Kniga, learning to hunt from a young age. After her family was killed by bandits, she sought refuge in the city, using her skills to survive.', inventory=['Longbow', 'Quiver of arrows', 'Hunting knife', 'Leather jerkin', 'Waterskin', 'Small pouch of coins'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn more about instructor here: https://python.useinstructor.com/"
      ],
      "metadata": {
        "id": "E9wSWooF9k_y"
      }
    }
  ]
}