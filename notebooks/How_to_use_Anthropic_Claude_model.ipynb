{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## How to use Anthropic Claude model\n",
        "In this notebook we look into:\n",
        "1. The basic on how to use an Anthropic model (Claude-3.5-Sonnet, and Claude-3.5-Haiku) with just a few lines of code\n",
        "2. Which settings you can play with to tune the behaviour of the model on your use case.\n"
      ],
      "metadata": {
        "id": "EmmlLw4H2F0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Table of content**\n",
        ">[Anthropic Setup](#folderId=1tp_6Ep8ifTiLdokzSoJhJccd212GnCHV&updateTitle=true&scrollTo=trNIWx9Av671)\n",
        "\n",
        ">[Simple inference with Claude model from Anthropic](#folderId=1tp_6Ep8ifTiLdokzSoJhJccd212GnCHV&updateTitle=true&scrollTo=UFa55z60wt72)\n",
        "\n",
        ">[Advanced Options](#folderId=1tp_6Ep8ifTiLdokzSoJhJccd212GnCHV&updateTitle=true&scrollTo=sLX3RCdD1FHF)\n",
        "\n",
        ">[Streaming](#folderId=1tp_6Ep8ifTiLdokzSoJhJccd212GnCHV&updateTitle=true&scrollTo=n2o2YPQl1t0s)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "j-HCVig92o0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anthropic Setup"
      ],
      "metadata": {
        "id": "trNIWx9Av671"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we have to install it (it i note available by default in Google Colab)\n",
        "!pip install anthropic --quiet"
      ],
      "metadata": {
        "id": "0ir6ypgVwIYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3323950b-c1bf-4518-a886-cf2bdc4e6f30"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/288.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.8/288.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f2uTnH7-tuEl"
      },
      "outputs": [],
      "source": [
        "import anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use an Anthropic Claude models, you'll need to create an API key and configure it in your Google Colab Secrets.\n",
        "\n",
        "\n",
        "1. Login or create an Anthropic account, and configure a billing method, on the Anthropic Console [here](https://console.anthropic.com/login).\n",
        "2. You'll also have to make provision a small amount of credit like $5 before you can start using the API.\n",
        "3. Create a secret api key from [here](https://console.anthropic.com/settings/keys)\n",
        "4. Open your Colab secrets (click on the key icon here on the left)\n",
        "3. Give a the name, for instance `ANTHROPIC_API_KEY`, and past the value in `Value`.\n",
        "4. Toggle `Notebook access` to give access to this specific notebook to the API key.\n",
        "\n",
        "🔑 Note that this api key will now be available in your secrets everytime you open or create a new colab notebook. You'll however still need to grant explicit access to each notebook.\n",
        "\n",
        "\n",
        "💸 Using an Anthropic model you will get charged! Use a small and cheap model for testing and learning like `claude-3-5-haiku-latest` then switch to a better model if needed for more complex tasks.\n"
      ],
      "metadata": {
        "id": "Tsh_FlQwulOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')"
      ],
      "metadata": {
        "id": "98VRNCvPvD_E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple inference with Claude model from Anthropic\n",
        "Text generation is very simple. You need to create an Antrhopic `client` object. You then call the `client.messages.create()` function and pass **the two most important parameters:**\n",
        "- 🧠 `model` the large language model being used.\n",
        "- 💬 `messages` the list of user messages, and assistant responses.\n",
        "\n",
        "It is very similar to OpenAI.\n",
        "\n",
        "Note: However with Anthropic, the optional system prompt does not go into the messages list, instead, it is an extra argument **system** like illustrated below (more on system prompt with Claude [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts)."
      ],
      "metadata": {
        "id": "UFa55z60wt72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anthropic Models\n",
        "I recommend testing models in the following order (from cheaper to more expensive and better):\n",
        "1. `claude-3-5-haiku-latest` affordable, intelligent and balzing fast.\n",
        "    - Knowledge cut-off date: July 2024\n",
        "2. `claude-sonnet-4-0` High intelligence and balanced performance.\n",
        "    - Knowledge cut-off date: March 2025\n",
        "3. `claude-opus-4-0`: Very expensive, but highest level of intelligence and capability\n",
        "    - Knowledge cut-off date: March 2025\n",
        "\n",
        "All models have a 200k tokens (150k english words) context window limits, i.e. the maximum size of input messages.\n",
        "\n",
        "For pricing and more info, look [here](https://docs.anthropic.com/en/docs/about-claude/models/overview#model-comparison-table)"
      ],
      "metadata": {
        "id": "T78jPP4dyKDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "\n",
        "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "response = client.messages.create(\n",
        "    model=\"claude-3-5-haiku-latest\",\n",
        "    max_tokens=2048,\n",
        "    system=\"You are the World best poet\", # <-- system prompt\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Write a very short poem about an astronaut on the Moon\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.content[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJnSG7KYwZtb",
        "outputId": "89d63b9f-4a3d-4141-d4cd-a045fa0d64f0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a short poem about an astronaut on the Moon:\n",
            "\n",
            "Footprints in dust, silent and bright,\n",
            "Alone on this pale, alien height.\n",
            "Earth hangs distant, a blue-green sphere,\n",
            "Silence echoes, no sound I hear.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Options\n",
        "Here are some more advanced parameters you can use."
      ],
      "metadata": {
        "id": "sLX3RCdD1FHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "\n",
        "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "response = client.messages.create(\n",
        "    model=\"claude-3-5-haiku-latest\",\n",
        "    system=\"You are the World best poet\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Write a very short poem about an astronaut on the Moon\"}\n",
        "        ],\n",
        "    max_tokens=512,\n",
        "    temperature=0.8,\n",
        "    top_k=10\n",
        ")"
      ],
      "metadata": {
        "id": "QoI03ISU1KsT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF4fISGW32i_",
        "outputId": "492ac1ac-19b8-4497-c669-0725c2265d16"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a short poem about an astronaut on the Moon:\n",
            "\n",
            "Footprints in dust, silent and bright,\n",
            "Lone explorer in lunar light,\n",
            "Earth hangs distant, blue and round,\n",
            "Stillness echoes without a sound.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the full documentation, check [here](https://docs.anthropic.com/en/api/messages). However, below are what I think the most important parameters to be aware of.\n",
        "\n",
        "**Temperature**\n",
        "\n",
        "- The `temperature` is the amount of randomness injected into the response. Defaults to 1.0. Ranges from 0.0 to 1.0. Use temperature closer to 0.0 for analytical / multiple choice, and closer to 1.0 for creative and generative tasks. Note that even with temperature of 0.0, the results will not be fully deterministic\n",
        "\n",
        "**Maximum number of tokens**\n",
        "\n",
        "- `max_token` refers to The maximum number of tokens to generate before stopping. Note that it may stop *before*.\n",
        "\n",
        "**Top K**\n",
        "\n",
        "- `top_k` top_k (integer) Only sample from the top K options for each subsequent token.\n",
        "\n",
        "**System**\n",
        "\n",
        "- `system` (string) a prompt you can use to set a role for the assistant."
      ],
      "metadata": {
        "id": "hL3WnKZ04_nH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming\n",
        "\n",
        "Without streaming you have to wait until the full response is created by the model to see it.\n",
        "With **streaming** you see each token as soos as they are generated, like in the Claude AI Chat interface. Streaming provide a much better user experience.\n",
        "Otherwise, if you don't have user-facing apps, you may not need it."
      ],
      "metadata": {
        "id": "n2o2YPQl1t0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "\n",
        "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "with client.messages.stream(\n",
        "    max_tokens=1024,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Write a very short poem about an astronaut on the Moon\"}],\n",
        "    model=\"claude-3-5-haiku-latest\",\n",
        ") as stream:\n",
        "  for text in stream.text_stream:\n",
        "      print(text, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKGsszS71uw4",
        "outputId": "9f8f2264-d335-4529-c4cd-c8ac00e202c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a short poem about an astronaut on the Moon:\n",
            "\n",
            "Silent steps on silver ground,\n",
            "Earth hangs distant, without a sound.\n",
            "Footprints etched in lunar dust,\n",
            "One small leap of human trust."
          ]
        }
      ]
    }
  ]
}