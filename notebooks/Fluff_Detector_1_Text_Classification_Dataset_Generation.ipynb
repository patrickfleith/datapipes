{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f63d3a9c41094ac9bb9808e02a08e9ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_326118652a2f48de8bf646ea9e3cc45c",
              "IPY_MODEL_85006b3fc2eb4a3497781eaa62d68c4b",
              "IPY_MODEL_da792392bd7d48c9b21087e2296a46be"
            ],
            "layout": "IPY_MODEL_a51a5ced7e394006aea4045af5434b18"
          }
        },
        "326118652a2f48de8bf646ea9e3cc45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b72149946fdd471089114feed7c40520",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6c4ce3f4612d4929afa7021521933bef",
            "value": "Uploadingâ€‡theâ€‡datasetâ€‡shards:â€‡100%"
          }
        },
        "85006b3fc2eb4a3497781eaa62d68c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_756ddc0a085442c487de18af36037061",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54e6bb99615b43cdae79650d64446be0",
            "value": 1
          }
        },
        "da792392bd7d48c9b21087e2296a46be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_858d6f4247d745bea212048c29d95f2b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_504b7ca611e64ae7813ce30c596cde0f",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡â€‡1.59it/s]"
          }
        },
        "a51a5ced7e394006aea4045af5434b18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72149946fdd471089114feed7c40520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c4ce3f4612d4929afa7021521933bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "756ddc0a085442c487de18af36037061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e6bb99615b43cdae79650d64446be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "858d6f4247d745bea212048c29d95f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "504b7ca611e64ae7813ce30c596cde0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "329b426abc224d0f9b4e7cf9acdeb27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68ebfad9f3bd4ec4b097c9705b6a17ce",
              "IPY_MODEL_05afcab7a1084011b3e0919c6a1415c4",
              "IPY_MODEL_e258b2b31b074765a1831c01b749b9e6"
            ],
            "layout": "IPY_MODEL_d3fdd4920b95493ab70ec477c574e898"
          }
        },
        "68ebfad9f3bd4ec4b097c9705b6a17ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d3550f1efb74c1fa056e9a1b1ded6e2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5479360552b746d298dd4d051c71acc0",
            "value": "Creatingâ€‡parquetâ€‡fromâ€‡Arrowâ€‡format:â€‡100%"
          }
        },
        "05afcab7a1084011b3e0919c6a1415c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_413a7d8bda8f48969410fc8d71d9b9f4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2c16fbdb26744ada64c945da47a6ae0",
            "value": 1
          }
        },
        "e258b2b31b074765a1831c01b749b9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bacfd09b853444487cdbc4b06984b06",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8ed1bc934ee247be81a87eb9edf9cb8e",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡45.36ba/s]"
          }
        },
        "d3fdd4920b95493ab70ec477c574e898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d3550f1efb74c1fa056e9a1b1ded6e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5479360552b746d298dd4d051c71acc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "413a7d8bda8f48969410fc8d71d9b9f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c16fbdb26744ada64c945da47a6ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bacfd09b853444487cdbc4b06984b06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed1bc934ee247be81a87eb9edf9cb8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fluff Detection: A Step Toward Concise Writing\n",
        "\n",
        "## Objective\n",
        "This project aims to develop a text classifier, in particular **a fluff detector** to identify and reduce verbosity in English writing. By categorizing and annotating instances of fluff, we can later fine-tune language models to rewrite text with clarity and precision.\n",
        "\n",
        "> **In this notebook we will focus on creating a small synthetic dataset to train a first version of the text classifier**\n",
        "\n",
        "## What Is Fluff?\n",
        "Fluff refers to superfluous elements in writing that increase length but do not enhance meaning.\n",
        "- It weakens clarity and reduce communication effectiveness.\n",
        "\n",
        "\n",
        "Below are examples illustrating common types of 'fluff' and overlaps:\n",
        "\n",
        "#### Example 1\n",
        "- **Fluffy**: *It is absolutely and completely necessary for us to thoroughly and carefully evaluate all aspects of the situation.* âŒ\n",
        "- **Concise**: *We must evaluate all aspects of the situation.* âœ…\n",
        "\n",
        "#### Example 2\n",
        "- **Fluffy**: *As I mentioned earlier, we actually need to start working on this project sooner rather than later to ensure that we meet the deadline.* âŒ\n",
        "- **Concise**: *We need to start this project soon to meet the deadline.* âœ…\n",
        "\n",
        "#### Example 3\n",
        "- **Fluffy**: *At the end of the day, we need to think outside the box to ensure that this project reaches its maximum potential.* âŒ\n",
        "- **Concise**: *We need creative ideas to make this project succeed.* âœ…\n",
        "\n"
      ],
      "metadata": {
        "id": "SQRBORPm9Cr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How Will We Build The Dataset?\n",
        "We want to minimize the time we take to build the dataset so we'll:\n",
        "- Define our labels and describe them.\n",
        "- Choose language\n",
        "- Describe the type of text entries we would like to generate, incuding prompt variations to create different styles, scenario, and intents.\n",
        "- Use a dataset of `Persona` to maximize diversity accross the potential writter of verbose / concise text."
      ],
      "metadata": {
        "id": "K7MDjdeyHZ0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Labels\n",
        "We will use the follow two simple labels:\n",
        "- **`fluffy`** - (also labelled `1`)\n",
        "- **`concise`** - (also labelled `0`)\n",
        "\n",
        "We'll also provide a descriptio for each label\n",
        "- `name`: The name of the label\n",
        "- `instruction`: this is a specific instruction to tell the LLM to generate either one label or the other.\n",
        "- `description`: this description will be used by the generative model clarify what our expectation behind our label.\n"
      ],
      "metadata": {
        "id": "OhSZfFQ_x5q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS = [\n",
        "    {\n",
        "        \"name\": \"fluffy\",\n",
        "        \"instruction\": \"Make sure that the text is realistic, but a bit verbose and with a bit of fluff.\",\n",
        "        \"description\": \"Fluff in text is often includes some redundancy, filler words, excessive qualifiers, unnecessary adjectives or adverbs, irrelevant information, and repetition of known context.\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"concise\",\n",
        "        \"instruction\": \"Make sure that the text is very concise, and compact.\",\n",
        "        \"description\": \"Concise text is characterized by clarity, precision, and brevity. It communicates ideas directly, in a very compact manner using only the words necessary to convey the intended message.\",\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "Uw3cehuzylQ1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Language\n",
        "We will choose language:\n",
        "- For simplicity we'll stick to **english**."
      ],
      "metadata": {
        "id": "6KmfRHeZ1Uaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LANGUAGES = {\"en\": \"English\"}\n",
        "# Could also be\n",
        "# LANGUAGES = {\n",
        "#     \"fr\": \"French\",\n",
        "#     \"es\": \"Spanish\",\n",
        "#     \"en\": \"English\"\n",
        "# }"
      ],
      "metadata": {
        "id": "V3hvV6cZ1hcY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description of Text Entries\n",
        "We would like to focus on classifying:\n",
        "- `sentence-level`: each text is short (1 or 2 sentences)\n",
        "\n",
        "To create a **realistic** dataset we need to inject **variations**.\n",
        "> For these **we will combine different styles, contexts, communication mediums and intents, together with unique personas.**\n",
        "- `persona`: text that could be written by a specific persona (more on that later)\n",
        "- `styles`: phrases written in different styles\n",
        "- `context`: phrases which can be written in different daily-context\n",
        "- `medium`: text that can be written on diferent medium\n",
        "- `intent`: different flavors of intent.\n",
        "\n",
        "All this will help us construct a procedural prompt for high-diversity, yet realistic texts.\n",
        "\n",
        "**Example Generation Prompt**:\n",
        "\n",
        "*Imagine 3 differents but realistic sentences which could have been written by the following person:*\n",
        "\n",
        "*Persona: Leo, A small wood manufacturing business owner who just got his first kid.*\n",
        "\n",
        "*Writting style: A tendency for exageration*\n",
        "\n",
        "*Context: In the middle of the night*\n",
        "\n",
        "*Medium: Email*\n",
        "\n",
        "*Intent: To warn somebody about something.*"
      ],
      "metadata": {
        "id": "MYrz4azc1g3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I would use HuggingChat, Claude or ChatGPT to generate some styles ideas, context, medium, and intents.\n",
        "\n",
        "> âš  These properties should be generic enough to not conflict with each other, and especially not conflict with one of the label."
      ],
      "metadata": {
        "id": "i4hHPZGu59_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STYLES = {\n",
        "    \"formal1\": \"Structured and professional, suitable for official contexts.\",\n",
        "    \"formal2\": \"Polished and respectful, adhering to formal conventions.\",\n",
        "    \"formal3\": \"Clear and authoritative, used for professional communication.\",\n",
        "    \"formal4\": \"Impersonal and precise, avoiding casual language.\",\n",
        "    \"formal5\": \"Serious and proper, often found in legal or academic writing.\",\n",
        "    \"technical1\": \"Detailed and precise, explaining concepts clearly.\",\n",
        "    \"technical2\": \"Jargon-heavy and factual, tailored for experts.\",\n",
        "    \"technical3\": \"Objective and structured, presenting data or instructions.\",\n",
        "    \"technical4\": \"Focused and methodical, designed for problem-solving.\",\n",
        "    \"technical5\": \"Concise and systematic, delivering technical details.\",\n",
        "    \"casual\": \"Relaxed and conversational, like chatting with a friend.\",\n",
        "    \"narrative\": \"Story-like, focused on events or characters in a sequence.\",\n",
        "    \"humorous\": \"Playful and witty, aimed at entertaining or amusing.\",\n",
        "    \"technical\": \"Precise and factual, used for scientific or detailed explanations.\",\n",
        "    \"persuasive\": \"Convincing and influential, designed to sway opinions or actions.\",\n",
        "    \"descriptive\": \"Vivid and detailed, creating a clear mental picture.\",\n",
        "    \"emotional\": \"Expressive and heartfelt, focused on feelings or personal views.\",\n",
        "    \"instructional\": \"Clear and step-by-step, aimed at guiding or teaching.\",\n",
        "    \"poetic\": \"Artistic and rhythmic, often using metaphors and imagery.\",\n",
        "    \"journalistic\": \"Objective and concise, focusing on facts and current events.\",\n",
        "    \"rhetorical\": \"Argumentative and impactful, designed to provoke thought.\"\n",
        "}"
      ],
      "metadata": {
        "id": "vi2-tMQy6dVE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXTS = {\n",
        "    \"professional_meeting\": \"During a meeting at work.\",\n",
        "    \"family_gathering\": \"During a family gathering.\",\n",
        "    \"public_event\": \"At a public event, like a concert or seminar.\",\n",
        "    \"social_media\": \"While scrolling through social media.\",\n",
        "    \"night_time\": \"Late at night, during quiet hours.\",\n",
        "    \"early_morning\": \"Early in the morning, starting the day.\",\n",
        "    \"evening\": \"In the evening, winding down after the day.\",\n",
        "    \"overtime\": \"Working late hours, beyond regular time.\",\n",
        "    \"travel_scenario\": \"While traveling or preparing for a trip.\",\n",
        "    \"celebratory_event\": \"During a joyful moment, like a party or achievement.\",\n",
        "    \"emergency_situation\": \"In an urgent or crisis situation requiring immediate action.\",\n",
        "    \"outdoor_activity\": \"While engaging in an activity outdoors, like hiking or picnicking.\",\n",
        "    \"quiet_reflection\": \"In a moment of calm reflection or introspection.\",\n",
        "    \"holiday_season\": \"During festive holidays or seasonal celebrations.\",\n",
        "    \"classroom_setting\": \"In a classroom or educational environment.\",\n",
        "    \"waiting_room\": \"While waiting at a doctorâ€™s office or similar space.\",\n",
        "    \"sports_event\": \"At a sports event, watching or participating.\",\n",
        "    \"work_from_home\": \"Working remotely from home.\",\n",
        "    \"traffic_jam\": \"Stuck in traffic or commuting.\",\n",
        "    \"coffee_shop\": \"Relaxing or working in a coffee shop.\",\n",
        "    \"shopping\": \"While shopping in a mall or store.\",\n",
        "    \"childcare\": \"Taking care of children or helping with homework.\",\n",
        "    \"fitness_activity\": \"During a workout or physical exercise session.\",\n",
        "    \"friend_gathering\": \"Hanging out with friends in a casual setting.\",\n",
        "    \"study_session\": \"Focused on studying or group learning.\",\n",
        "    \"online_meeting\": \"During a video conference or virtual call.\"\n",
        "}"
      ],
      "metadata": {
        "id": "7S0fi3T81Q6z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MEDIUMS = {\n",
        "    \"email\": \"email\",\n",
        "    \"text_message\": \"A quick text message\",\n",
        "    \"social_media_post\": \"A post or comment shared on social media platforms.\",\n",
        "    \"technical_document\": \"Technical document\",\n",
        "    \"paper\": \"Scientific paper\",\n",
        "    \"book\": \"Book\",\n",
        "    \"personal_note\": \"Personal notes\",\n",
        "}"
      ],
      "metadata": {
        "id": "cKX6nM9r1Q3u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INTENTS = {\n",
        "    \"inform\": \"To provide information or knowledge to the reader.\",\n",
        "    \"warn\": \"To alert or caution the reader about potential risks or dangers.\",\n",
        "    \"entertain\": \"To amuse or captivate the reader through engaging content.\",\n",
        "    \"motivate\": \"To inspire or encourage the reader to take action or feel uplifted.\",\n",
        "    \"persuade\": \"To convince the reader to agree with a point of view or take a specific action.\",\n",
        "    \"reflect\": \"To ponder or explore thoughts, emotions, or experiences.\",\n",
        "    \"request\": \"To ask for information, action, or assistance from the reader.\",\n",
        "    \"express_gratitude\": \"To show appreciation or thanks to the reader.\"\n",
        "}"
      ],
      "metadata": {
        "id": "ONJFPuSu1Q0g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we are ready to put everything together for a prompt template.\n",
        "> *With the large diversity of personas, and the contextual variations set above, this will create several different prompt to optimize for diversity*"
      ],
      "metadata": {
        "id": "-ht8G497TD9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = \"\"\"Imagine {num_entries} differents and realistic sentences which could have been written by the following person:\n",
        "Persona: {persona}\n",
        "Writting style: {style}\n",
        "Context: {context}\n",
        "Medium: {medium}\n",
        "Intent: {intent}\n",
        "\n",
        "Instructions:\n",
        "Each text entry must be short (1 to 2) sentences max.\n",
        "The core idea in each text entry must be different from the others.\n",
        "The language must be {language}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "G7tHB3Pa_Z-r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the prompt construction in action"
      ],
      "metadata": {
        "id": "ABVUuaYETarN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_prompt = PROMPT_TEMPLATE.format(\n",
        "    persona = \"Leo, A small wood manufacturing business owner who just got his first kid.\",\n",
        "    num_entries = 2,\n",
        "    style = STYLES['humorous'],\n",
        "    context = CONTEXTS['night_time'],\n",
        "    medium = MEDIUMS[\"social_media_post\"],\n",
        "    intent = INTENTS[\"request\"],\n",
        "    language=LANGUAGES['en']\n",
        ")\n",
        "\n",
        "print(generation_prompt)"
      ],
      "metadata": {
        "id": "xIL78bjX_ZxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7db0b2-43b2-42ba-9d67-f8031c45d261"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine 2 differents and realistic sentences which could have been written by the following person:\n",
            "Persona: Leo, A small wood manufacturing business owner who just got his first kid.\n",
            "Writting style: Playful and witty, aimed at entertaining or amusing.\n",
            "Context: Late at night, during quiet hours.\n",
            "Medium: A post or comment shared on social media platforms.\n",
            "Intent: To ask for information, action, or assistance from the reader.\n",
            "\n",
            "Instructions:\n",
            "Each text entry must be short (1 to 2) sentences max.\n",
            "The core idea in each text entry must be different from the others.\n",
            "The language must be English\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google Gemini\n",
        "Now that we can generate many different prompts, it's time to generate responses.\n",
        "\n",
        "To generate samples we will:\n",
        "- Choose an LLM: we'll use *`gemini-1.5-flash`* which has a **15 RPM (request per minute) quota and 1,500 RPD (request per day)**.\n",
        "    - It's not huge but given this is free, it's great!\n",
        "\n",
        "- Configure sutructured Outputs: we'll use pydantic and the intructor library to force gemini to answer following a specific format."
      ],
      "metadata": {
        "id": "wjwwqiI1CFwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install instructor datasets --quiet"
      ],
      "metadata": {
        "id": "uNFXq7J3Ue5l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from datasets import load_dataset\n",
        "from pydantic import BaseModel\n",
        "import instructor\n",
        "import random\n",
        "import uuid\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "O2W2VBfWBK4e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to know more about working with Gemini, I have a few tutorial notebooks [here](https://patrickfleith.github.io/datapipes/?utm_source=notebooks&utm_medium=colab&utm_campaign=notebooks) which I try to keep up-to-date."
      ],
      "metadata": {
        "id": "JQ7zKTc_6j3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup your API in Colab Secrets and read it here. Pass it to genai to interact with Gemini.\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "4h-cA2mmBK1K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's instantiate a model and try it\n",
        "MODEL_ID = \"gemini-1.5-flash\"\n",
        "model = genai.GenerativeModel(model_name=MODEL_ID)\n",
        "response = model.generate_content(generation_prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "fBf0bV7jBKyV",
        "outputId": "54d23574-ab81-4f70-cafe-e5d96b4791ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.  \"So, the tiny human finally decided sleep is overrated. Anyone got tips on surviving on 3 hours of sleep AND running a woodworking business? Send coffee (and maybe a nap pod).\"\n",
            "\n",
            "2.  \"My sawdust-covered workshop is officially a baby-proofing nightmare.  Seriously, any recommendations for child-safe woodworking clamps?  Asking for a sleep-deprived, slightly frantic, father-carpenter.\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the class for structured output\n"
      ],
      "metadata": {
        "id": "xhBOScQqVCJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Pydantic models enables to automatically create a \"JSON\" schema which is described to the LLM at inference time, and which will be used by `instructor` to remove illegal tokens. If you want to better understand how to generate structured outputs, checkout my guides [here](https://patrickfleith.github.io/datapipes/?utm_source=notebooks&utm_medium=colab&utm_campaign=notebooks)"
      ],
      "metadata": {
        "id": "0YP2r62q7eSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class TextEntries(BaseModel):\n",
        "    entries: list[str] = Field(\n",
        "        ...,\n",
        "        description=\"List of texts\"\n",
        "    )"
      ],
      "metadata": {
        "id": "H8IZ2t6HDcTg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can access the JSON Schema\n",
        "TextEntries.model_json_schema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmkdGC6cb-20",
        "outputId": "aa5bb41d-65d5-4a33-baf6-a00b19efaf50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'properties': {'entries': {'description': 'List of texts',\n",
              "   'items': {'type': 'string'},\n",
              "   'title': 'Entries',\n",
              "   'type': 'array'}},\n",
              " 'required': ['entries'],\n",
              " 'title': 'TextEntries',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We instantiate a client with instructor *from the google_client* to follow the desired structured outputs"
      ],
      "metadata": {
        "id": "ENDReBQCVFHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_client = genai.GenerativeModel(\n",
        "    model_name=MODEL_ID)\n",
        "\n",
        "client = instructor.from_gemini(\n",
        "    client=google_client,\n",
        "    mode=instructor.Mode.GEMINI_JSON,\n",
        ")"
      ],
      "metadata": {
        "id": "pHEluhvNDcQh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Persona\n",
        "As for the persona, we'll be using the **`FinePersonas`** dataset, an Open dataset of 21 million detailed personas, which has specifically been built for diverse and controllable synthetic text generation.\n",
        "\n",
        "ðŸ‘ Big kudos to the [Argilla](https://argilla.io/) team for this dataset.\n",
        "You can find this dataset [here](https://huggingface.co/datasets/argilla/FinePersonas-v0.1)"
      ],
      "metadata": {
        "id": "AOEAyOvnCkE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fine_personas_dataset = load_dataset(\"argilla/FinePersonas-v0.1\", \"default\")"
      ],
      "metadata": {
        "id": "QrNEWldLHgtM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will not need the 21 millions personas ðŸ˜…\n",
        "- 400 for the train set.\n",
        "- 100 for the test set.\n",
        "\n",
        "For each persona will generate *`N`* texts for each of the 2 class (fluff or concise). This mean:\n",
        "- 800 GEMINI API requests (1600 generated datapoints) in the train set\n",
        "- 200 GEMINI API requests (400  generated datapoints) in the test set\n",
        "\n",
        "âœ… This comply with the quota of 1500 RPD\n",
        "\n",
        "âœ… This will result in a dataset of 2k examples (1600 train + 400 test).\n",
        "\n",
        "> Below I actually use a ratio of 40/10 to run the notebook faster."
      ],
      "metadata": {
        "id": "TKdL9CJ4bla-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "personas = fine_personas_dataset['train'].train_test_split(\n",
        "    train_size=40,\n",
        "    test_size=10,\n",
        "    shuffle=True,\n",
        "    seed=15)"
      ],
      "metadata": {
        "id": "YXRfLliIHghz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the reduced dataset"
      ],
      "metadata": {
        "id": "5pPdbj4hcCZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "personas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVhjiyPkDb_a",
        "outputId": "22f1a38f-3c74-4b5c-8bbd-b30a831887b5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'persona', 'labels'],\n",
              "        num_rows: 40\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'persona', 'labels'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check an example persona from the dataset\n",
        "personas['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfeCjdvgFN3m",
        "outputId": "084cf40f-24f3-4ee2-c499-5aa589343279"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '<urn:uuid:b5cbc9da-10e6-4be1-bc90-ef8ed3cc99c5>',\n",
              " 'persona': 'An environmentally conscious middle school student who is interested in science and is doing a project on deforestation, its causes, effects and potential solutions.',\n",
              " 'labels': '[\"Environmental\", \"Scientific\", \"Professional\"]'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities\n",
        "- One function that will randomy pick one variations among styles, itents, languages, etc...\n",
        "- One function which, given the prompt template and the randomised variable will construct the prompt.\n",
        "    - This function also adds special instruction for Gemini to generate either **fluffy** or **concise** texts."
      ],
      "metadata": {
        "id": "agcq7uuaFcwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_one(variations):\n",
        "    \"\"\" Randomly pick a variation among several possible styles, intents, mediums, contexts, languages \"\"\"\n",
        "    random_variation_key = random.choice(list(variations.keys()))\n",
        "    random_variation_value = variations[random_variation_key]\n",
        "    return random_variation_value"
      ],
      "metadata": {
        "id": "fgWayaEwGUvm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(num_entries, persona, style, context, medium, intent, language, label_idx):\n",
        "    generation_prompt = PROMPT_TEMPLATE.format(\n",
        "        persona = persona,\n",
        "        num_entries = num_entries,\n",
        "        style = style,\n",
        "        context = context,\n",
        "        medium = medium,\n",
        "        intent = intent,\n",
        "        language = language\n",
        "    )\n",
        "\n",
        "    final_prompt = generation_prompt + f\"\\n{LABELS[label_idx]['instruction']} {LABELS[label_idx]['description']}\"\n",
        "\n",
        "    return final_prompt"
      ],
      "metadata": {
        "id": "n8ScUOABwz5d"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation Time â°\n",
        "- We loop over each persona\n",
        "- We generate a unique prompt for each label (fluff, concise)\n",
        "- We generate a model response for each label\n",
        "- We extract the generated text from our structured outputs and store them in a dictionary\n",
        "- We add some counter to avoid exceeding Gemini Quota and try/except to catch potential errors."
      ],
      "metadata": {
        "id": "804Qast785eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we'll store our data in this dictionary\n",
        "dataset_dict = {\n",
        "    'uuid': [],\n",
        "    'persona': [],\n",
        "    'text': [],\n",
        "    'label': [],\n",
        "    'model': []\n",
        "    }"
      ],
      "metadata": {
        "id": "apfowXsxzGbM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we set two counters make sure we don't exceed quote. We pause before exceeding quota.\n",
        "rpd_counter = 0\n",
        "rpm_counter = 0\n",
        "\n",
        "for persona in personas['train']:\n",
        "\n",
        "    for label_idx, label in enumerate(LABELS):\n",
        "\n",
        "        prompt = generate_prompt(\n",
        "            num_entries=2,  # we will generate two texts for each LLM call\n",
        "            persona=persona['persona'],\n",
        "            style=pick_one(STYLES),\n",
        "            context=pick_one(CONTEXTS),\n",
        "            medium=pick_one(MEDIUMS),\n",
        "            intent=pick_one(INTENTS),\n",
        "            language=pick_one(LANGUAGES),  # only english in this example notebook\n",
        "            label_idx=label_idx,  # label for class 'fluff' and index in LABELS\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            model_response = client.messages.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a helpful AI Assistant\"},\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": prompt},\n",
        "                ],\n",
        "                response_model=TextEntries\n",
        "            )\n",
        "\n",
        "            try:\n",
        "                for entry in model_response.entries:\n",
        "                    dataset_dict['uuid'].append(str(uuid.uuid4()))  # Generate a unique ID\n",
        "                    dataset_dict['persona'].append(persona['persona'])\n",
        "                    dataset_dict['text'].append(entry)\n",
        "                    dataset_dict['label'].append(label_idx)\n",
        "                    dataset_dict['model'].append(MODEL_ID)\n",
        "            except:\n",
        "                print(\"Error saving record in dataset dictionary\")\n",
        "\n",
        "        except:\n",
        "            print(\"Error calling model\")\n",
        "            time.sleep(10) # wait for 10s if an exception occured.\n",
        "            pass\n",
        "\n",
        "    rpd_counter += 2\n",
        "    if rpd_counter > 1200:\n",
        "        break\n",
        "\n",
        "    print(f\"{rpd_counter//2} personas --- Generated a total of {rpd_counter*2} instances so far\")\n",
        "\n",
        "    rpm_counter += 2\n",
        "    if rpm_counter >= 14:\n",
        "        print(\"Quota pause...\")\n",
        "        time.sleep(60)\n",
        "        rpm_counter = 0"
      ],
      "metadata": {
        "id": "j3rWfr2kFawY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "outputId": "ee876867-c76a-4f2b-c905-9bb169752b8a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 personas --- Generated a total of 4 instances so far\n",
            "2 personas --- Generated a total of 8 instances so far\n",
            "3 personas --- Generated a total of 12 instances so far\n",
            "4 personas --- Generated a total of 16 instances so far\n",
            "5 personas --- Generated a total of 20 instances so far\n",
            "6 personas --- Generated a total of 24 instances so far\n",
            "7 personas --- Generated a total of 28 instances so far\n",
            "Quota pause...\n",
            "8 personas --- Generated a total of 32 instances so far\n",
            "9 personas --- Generated a total of 36 instances so far\n",
            "10 personas --- Generated a total of 40 instances so far\n",
            "11 personas --- Generated a total of 44 instances so far\n",
            "12 personas --- Generated a total of 48 instances so far\n",
            "13 personas --- Generated a total of 52 instances so far\n",
            "14 personas --- Generated a total of 56 instances so far\n",
            "Quota pause...\n",
            "15 personas --- Generated a total of 60 instances so far\n",
            "16 personas --- Generated a total of 64 instances so far\n",
            "17 personas --- Generated a total of 68 instances so far\n",
            "18 personas --- Generated a total of 72 instances so far\n",
            "19 personas --- Generated a total of 76 instances so far\n",
            "20 personas --- Generated a total of 80 instances so far\n",
            "21 personas --- Generated a total of 84 instances so far\n",
            "Quota pause...\n",
            "22 personas --- Generated a total of 88 instances so far\n",
            "23 personas --- Generated a total of 92 instances so far\n",
            "24 personas --- Generated a total of 96 instances so far\n",
            "25 personas --- Generated a total of 100 instances so far\n",
            "26 personas --- Generated a total of 104 instances so far\n",
            "27 personas --- Generated a total of 108 instances so far\n",
            "28 personas --- Generated a total of 112 instances so far\n",
            "Quota pause...\n",
            "29 personas --- Generated a total of 116 instances so far\n",
            "30 personas --- Generated a total of 120 instances so far\n",
            "31 personas --- Generated a total of 124 instances so far\n",
            "32 personas --- Generated a total of 128 instances so far\n",
            "33 personas --- Generated a total of 132 instances so far\n",
            "34 personas --- Generated a total of 136 instances so far\n",
            "35 personas --- Generated a total of 140 instances so far\n",
            "Quota pause...\n",
            "36 personas --- Generated a total of 144 instances so far\n",
            "37 personas --- Generated a total of 148 instances so far\n",
            "38 personas --- Generated a total of 152 instances so far\n",
            "39 personas --- Generated a total of 156 instances so far\n",
            "40 personas --- Generated a total of 160 instances so far\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "ds = Dataset.from_dict(dataset_dict)"
      ],
      "metadata": {
        "id": "Yb3hKr5WzluE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghNQVT_XlLD7",
        "outputId": "caae8e12-a6eb-43ad-bb26-6b1fc213471c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['uuid', 'persona', 'text', 'label', 'model'],\n",
              "    num_rows: 160\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ¥³ **We have our dataset and we can push it to the hub!**"
      ],
      "metadata": {
        "id": "yxfy1pesh80T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HF_USERNAME=\"patrickfleith\" # <--- replace with yours otherwise this won't work!\n",
        "PRIVATE = False # choose if you want a private dataset. If false it will be public.\n",
        "\n",
        "ds.push_to_hub(\n",
        "    repo_id=f'{HF_USERNAME}/fluff-vs-concise-demo',\n",
        "    private=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "f63d3a9c41094ac9bb9808e02a08e9ea",
            "326118652a2f48de8bf646ea9e3cc45c",
            "85006b3fc2eb4a3497781eaa62d68c4b",
            "da792392bd7d48c9b21087e2296a46be",
            "a51a5ced7e394006aea4045af5434b18",
            "b72149946fdd471089114feed7c40520",
            "6c4ce3f4612d4929afa7021521933bef",
            "756ddc0a085442c487de18af36037061",
            "54e6bb99615b43cdae79650d64446be0",
            "858d6f4247d745bea212048c29d95f2b",
            "504b7ca611e64ae7813ce30c596cde0f",
            "329b426abc224d0f9b4e7cf9acdeb27a",
            "68ebfad9f3bd4ec4b097c9705b6a17ce",
            "05afcab7a1084011b3e0919c6a1415c4",
            "e258b2b31b074765a1831c01b749b9e6",
            "d3fdd4920b95493ab70ec477c574e898",
            "4d3550f1efb74c1fa056e9a1b1ded6e2",
            "5479360552b746d298dd4d051c71acc0",
            "413a7d8bda8f48969410fc8d71d9b9f4",
            "e2c16fbdb26744ada64c945da47a6ae0",
            "5bacfd09b853444487cdbc4b06984b06",
            "8ed1bc934ee247be81a87eb9edf9cb8e"
          ]
        },
        "id": "j7tHPK4blMUB",
        "outputId": "f7b315f9-1c7e-4488-f3c6-e445af2a5dbb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f63d3a9c41094ac9bb9808e02a08e9ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "329b426abc224d0f9b4e7cf9acdeb27a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/patrickfleith/fluff-vs-concise-demo/commit/628ac0a95a7d9a85946f3504ef6d72a3b972e79d', commit_message='Upload dataset', commit_description='', oid='628ac0a95a7d9a85946f3504ef6d72a3b972e79d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/patrickfleith/fluff-vs-concise-demo', endpoint='https://huggingface.co', repo_type='dataset', repo_id='patrickfleith/fluff-vs-concise-demo'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}